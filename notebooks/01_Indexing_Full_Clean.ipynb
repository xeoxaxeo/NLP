{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-27T03:02:48.596772Z",
     "start_time": "2025-11-27T01:07:27.929236Z"
    }
   },
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "from typing import List\n",
    "from tqdm.notebook import tqdm\n",
    "from kiwipiepy import Kiwi\n",
    "from datasets import load_dataset\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path('..').resolve()\n",
    "DATA_DIR = PROJECT_ROOT / 'data'\n",
    "DB_DIR = PROJECT_ROOT / 'database'\n",
    "\n",
    "DB_PATH = DB_DIR / 'inverted_index_full_clean.db'\n",
    "\n",
    "for d in [DATA_DIR, DB_DIR]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "if not (DATA_DIR / 'corpus.pkl').exists():\n",
    "    print(\"데이터셋 다운로드 중\")\n",
    "    queries = load_dataset(\"junyoungson/KomuRetrieval\", \"queries\", split=\"queries\")\n",
    "    corpus = load_dataset(\"junyoungson/KomuRetrieval\", \"corpus\", split=\"corpus\")\n",
    "    qrels = load_dataset(\"junyoungson/KomuRetrieval\", split=\"test\")\n",
    "\n",
    "    full_corpus = [item for item in tqdm(corpus, desc=\"Corpus Loading\")]\n",
    "    full_queries = [item for item in tqdm(queries, desc=\"Queries Loading\")]\n",
    "    full_qrels = [item for item in tqdm(qrels, desc=\"Qrels Loading\")]\n",
    "\n",
    "    with open(DATA_DIR / 'corpus.pkl', 'wb') as f:\n",
    "        pickle.dump(full_corpus, f)\n",
    "    with open(DATA_DIR / 'queries.pkl', 'wb') as f:\n",
    "        pickle.dump(full_queries, f)\n",
    "    with open(DATA_DIR / 'qrels.pkl', 'wb') as f:\n",
    "        pickle.dump(full_qrels, f)\n",
    "else:\n",
    "    print(\"기존 데이터 로드 중\")\n",
    "    with open(DATA_DIR / 'corpus.pkl', 'rb') as f:\n",
    "        full_corpus = pickle.load(f)\n",
    "\n",
    "corpus = full_corpus\n",
    "print(f\"전체 데이터 사용: {len(corpus):,}개\")\n",
    "\n",
    "kiwi = Kiwi(num_workers=-1)\n",
    "\n",
    "STOPWORDS = {\n",
    "    '나오', '경우', '보이', '이후', '사람', '정도', '자신', '사용', '가능', '대하',\n",
    "    '위하', '사실', '만들', '등장', '문제', '모습', '시작', '가지', '생각', '따르',\n",
    "    '이상', '함께', '당시', '상대', '시간', '다시', '상황', '이름', '가장', '또한',\n",
    "    '모두', '결국', '다만', '많이', '달리', '다르', '물론', '당하', '처음', '현재',\n",
    "    '같이', '이유', '통하', '역시', '자체', '거의', '매우', '없이', '상태', '바로',\n",
    "    '인하', '특히', '존재', '들어가', '사이', '다음', '모르', '참고', '부분', '이것',\n",
    "    '해당', '그냥', '마지막', '필요', '부르', '관련', '떨어지', '대부분', '때문', '아니'\n",
    "}\n",
    "\n",
    "def tokenize(text: str) -> List[str]:\n",
    "    if not text: return []\n",
    "\n",
    "    text = text.replace('\\x00', '')\n",
    "    text = re.sub(r'~~.*?~~', '', text)\n",
    "    text = re.sub(r'[ㄱ-ㅎㅏ-ㅣ]+', '', text)\n",
    "    text = re.sub(r'[\\.\\?\\!~\\-]{2,}', '.', text)\n",
    "\n",
    "    try:\n",
    "        tokens = kiwi.tokenize(text)\n",
    "        useful_tags = ['NNG', 'NNP', 'VV', 'VA', 'MAG']\n",
    "\n",
    "        result = []\n",
    "        for t in tokens:\n",
    "            if t.tag in useful_tags and len(t.form) > 1:\n",
    "                if t.form not in STOPWORDS:\n",
    "                    result.append(t.form)\n",
    "        return result\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "def build_index_db(corpus):\n",
    "    conn = sqlite3.connect(str(DB_PATH))\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    for table in ['documents', 'inverted_index', 'statistics', 'term_stats']:\n",
    "        cursor.execute(f\"DROP TABLE IF EXISTS {table}\")\n",
    "\n",
    "    cursor.execute(\"CREATE TABLE documents (doc_id TEXT PRIMARY KEY, title TEXT, length INTEGER, tokens TEXT)\")\n",
    "    cursor.execute(\"CREATE TABLE inverted_index (term TEXT, doc_id TEXT, tf INTEGER, PRIMARY KEY (term, doc_id))\")\n",
    "    cursor.execute(\"CREATE TABLE statistics (key TEXT PRIMARY KEY, value REAL)\")\n",
    "    cursor.execute(\"CREATE TABLE term_stats (term TEXT PRIMARY KEY, df INTEGER)\")\n",
    "\n",
    "    inverted_index = defaultdict(lambda: defaultdict(int))\n",
    "    doc_lengths = {}\n",
    "    doc_data = []\n",
    "\n",
    "    print(f\"Index 구축 시작 (Target: {DB_PATH.name})\")\n",
    "    for doc in tqdm(corpus, desc=\"Indexing\"):\n",
    "        doc_id = doc['_id']\n",
    "        full_text = f\"{doc['title']} {doc['text']}\"\n",
    "        tokens = tokenize(full_text)\n",
    "\n",
    "        doc_lengths[doc_id] = len(tokens)\n",
    "        doc_data.append((doc_id, doc['title'], len(tokens), json.dumps(tokens, ensure_ascii=False)))\n",
    "\n",
    "        counts = Counter(tokens)\n",
    "        for term, tf in counts.items():\n",
    "            inverted_index[term][doc_id] = tf\n",
    "\n",
    "        if len(doc_data) >= 1000:\n",
    "            cursor.executemany(\"INSERT INTO documents VALUES (?, ?, ?, ?)\", doc_data)\n",
    "            conn.commit()\n",
    "            doc_data = []\n",
    "\n",
    "    if doc_data:\n",
    "        cursor.executemany(\"INSERT INTO documents VALUES (?, ?, ?, ?)\", doc_data)\n",
    "        conn.commit()\n",
    "\n",
    "    index_data = []\n",
    "    term_stats_data = []\n",
    "\n",
    "    print(\"역색인 저장\")\n",
    "    for term, postings in tqdm(inverted_index.items(), desc=\"Saving Index\"):\n",
    "        term_stats_data.append((term, len(postings)))\n",
    "        for doc_id, tf in postings.items():\n",
    "            index_data.append((term, doc_id, tf))\n",
    "\n",
    "        if len(index_data) >= 10000:\n",
    "            cursor.executemany(\"INSERT INTO inverted_index VALUES (?, ?, ?)\", index_data)\n",
    "            conn.commit()\n",
    "            index_data = []\n",
    "\n",
    "    if index_data:\n",
    "        cursor.executemany(\"INSERT INTO inverted_index VALUES (?, ?, ?)\", index_data)\n",
    "\n",
    "    cursor.executemany(\"INSERT INTO term_stats VALUES (?, ?)\", term_stats_data)\n",
    "\n",
    "    N = len(corpus)\n",
    "    avgdl = sum(doc_lengths.values()) / N if N > 0 else 0\n",
    "    cursor.executemany(\"INSERT INTO statistics VALUES (?, ?)\", [\n",
    "        ('N', N), ('avgdl', avgdl), ('total_terms', len(inverted_index))\n",
    "    ])\n",
    "\n",
    "    print(\"인덱스 생성\")\n",
    "    cursor.execute(\"CREATE INDEX idx_term ON inverted_index(term)\")\n",
    "    cursor.execute(\"CREATE INDEX idx_doc_id ON inverted_index(doc_id)\")\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(f\"DB 구축 완료: {DB_PATH}\")\n",
    "\n",
    "build_index_db(corpus)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기존 데이터 로드 중\n",
      "전체 데이터 사용: 50,222개\n",
      "Index 구축 시작 (Target: inverted_index_full_clean.db)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Indexing:   0%|          | 0/50222 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "71012ea3765a46f3b3e380e6e21d4c01"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "역색인 저장\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Saving Index:   0%|          | 0/474939 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "839af274b4d14f2cb0f65a5cb0c1a166"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인덱스 생성\n",
      "DB 구축 완료: C:\\Users\\cse\\Desktop\\xeoxaxeo\\NLP\\database\\inverted_index_full_clean.db\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
