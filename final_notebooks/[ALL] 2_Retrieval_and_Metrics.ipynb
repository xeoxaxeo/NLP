{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T14:40:14.107607Z",
     "start_time": "2025-12-09T14:40:09.310135Z"
    }
   },
   "source": "!pip install statsmodels pandas numpy tqdm kiwipiepy",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: statsmodels in c:\\users\\cse\\desktop\\xeoxaxeo\\nlp\\.venv\\lib\\site-packages (0.14.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\cse\\desktop\\xeoxaxeo\\nlp\\.venv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\cse\\desktop\\xeoxaxeo\\nlp\\.venv\\lib\\site-packages (2.3.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\cse\\desktop\\xeoxaxeo\\nlp\\.venv\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: kiwipiepy in c:\\users\\cse\\desktop\\xeoxaxeo\\nlp\\.venv\\lib\\site-packages (0.22.1)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in c:\\users\\cse\\desktop\\xeoxaxeo\\nlp\\.venv\\lib\\site-packages (from statsmodels) (1.16.3)\n",
      "Requirement already satisfied: patsy>=0.5.6 in c:\\users\\cse\\desktop\\xeoxaxeo\\nlp\\.venv\\lib\\site-packages (from statsmodels) (1.0.2)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\cse\\desktop\\xeoxaxeo\\nlp\\.venv\\lib\\site-packages (from statsmodels) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\cse\\desktop\\xeoxaxeo\\nlp\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cse\\desktop\\xeoxaxeo\\nlp\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\cse\\desktop\\xeoxaxeo\\nlp\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\cse\\desktop\\xeoxaxeo\\nlp\\.venv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: kiwipiepy_model<0.23,>=0.22 in c:\\users\\cse\\desktop\\xeoxaxeo\\nlp\\.venv\\lib\\site-packages (from kiwipiepy) (0.22.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cse\\desktop\\xeoxaxeo\\nlp\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T14:41:03.018065Z",
     "start_time": "2025-12-09T14:40:14.107607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import pickle\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from kiwipiepy import Kiwi\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "BASE_DIR = os.path.join('..')\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'final_data')\n",
    "DB_DIR = os.path.join(BASE_DIR, 'final_database')\n",
    "FULL_DATA_PATH = os.path.join(DATA_DIR, 'full_data.pkl')\n",
    "QUERIES_PATH = os.path.join(BASE_DIR, 'data', 'queries.pkl')\n",
    "QRELS_PATH = os.path.join(BASE_DIR, 'data', 'qrels.pkl')\n",
    "\n",
    "os.makedirs(DB_DIR, exist_ok=True)\n",
    "DB_PATH = os.path.join(DB_DIR, 'search_index_full.db')\n",
    "\n",
    "print(\"데이터 로드\")\n",
    "df = pd.read_pickle(FULL_DATA_PATH)\n",
    "\n",
    "if '_id' in df.columns:\n",
    "    df.set_index('_id', inplace=True)\n",
    "elif 'doc_id' in df.columns:\n",
    "    df.set_index('doc_id', inplace=True)\n",
    "df.index = df.index.astype(str)\n",
    "\n",
    "with open(QUERIES_PATH, 'rb') as f:\n",
    "    queries_data = pickle.load(f)\n",
    "with open(QRELS_PATH, 'rb') as f:\n",
    "    qrels_data = pickle.load(f)"
   ],
   "id": "dc3a9329939ff0bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로드\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T14:56:28.811804Z",
     "start_time": "2025-12-09T14:56:28.768151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if os.path.exists(DB_PATH):\n",
    "    os.remove(DB_PATH)\n",
    "\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "cursor = conn.cursor()\n",
    "cursor.execute('CREATE TABLE inverted_index (term TEXT, doc_id TEXT, tf INTEGER)')\n",
    "cursor.execute('CREATE INDEX idx_term ON inverted_index(term)')\n",
    "\n",
    "print(\"역색인 구축 (패딩 'O' 제외)\")\n",
    "data_to_insert = []\n",
    "BATCH_SIZE = 50000\n",
    "\n",
    "doc_freq = {}\n",
    "total_docs = len(df)\n",
    "avg_dl = df['doc_length'].mean()\n",
    "\n",
    "for doc_id, row in tqdm(df.iterrows(), total=total_docs, desc=\"Indexing\"):\n",
    "    tokens = row['tokens_padded']\n",
    "    term_counts = {}\n",
    "\n",
    "    for t in tokens:\n",
    "        if set(t) == {'O'}: continue\n",
    "        term_counts[t] = term_counts.get(t, 0) + 1\n",
    "\n",
    "    for term, tf in term_counts.items():\n",
    "        data_to_insert.append((term, str(doc_id), tf))\n",
    "        doc_freq[term] = doc_freq.get(term, 0) + 1\n",
    "\n",
    "    if len(data_to_insert) >= BATCH_SIZE:\n",
    "        cursor.executemany('INSERT INTO inverted_index VALUES (?, ?, ?)', data_to_insert)\n",
    "        data_to_insert = []\n",
    "\n",
    "if data_to_insert:\n",
    "    cursor.executemany('INSERT INTO inverted_index VALUES (?, ?, ?)', data_to_insert)\n",
    "conn.commit()\n",
    "print(\"인덱싱 완료\")"
   ],
   "id": "fce6bea7fca69066",
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[WinError 32] 다른 프로세스가 파일을 사용 중이기 때문에 프로세스가 액세스 할 수 없습니다: '..\\\\final_database\\\\search_index_full.db'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mPermissionError\u001B[39m                           Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m os.path.exists(DB_PATH):\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m     \u001B[43mos\u001B[49m\u001B[43m.\u001B[49m\u001B[43mremove\u001B[49m\u001B[43m(\u001B[49m\u001B[43mDB_PATH\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      4\u001B[39m conn = sqlite3.connect(DB_PATH)\n\u001B[32m      5\u001B[39m cursor = conn.cursor()\n",
      "\u001B[31mPermissionError\u001B[39m: [WinError 32] 다른 프로세스가 파일을 사용 중이기 때문에 프로세스가 액세스 할 수 없습니다: '..\\\\final_database\\\\search_index_full.db'"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "kiwi = Kiwi(num_workers=0)\n",
    "idf_cache = {t: math.log((total_docs - df + 0.5) / (df + 0.5) + 1) for t, df in doc_freq.items()}\n",
    "\n",
    "def tokenize_query(text):\n",
    "    try:\n",
    "        return [t.form for t in kiwi.tokenize(text) if t.tag in ['NNG', 'NNP', 'VV', 'VA', 'MAG']]\n",
    "    except: return []\n",
    "\n",
    "def calculate_scores(query_tokens, model_type='BM25', k1=1.2, b=0.75):\n",
    "    scores = {}\n",
    "    for term in query_tokens:\n",
    "        if term not in idf_cache: continue\n",
    "        idf = idf_cache[term]\n",
    "\n",
    "        cursor.execute('SELECT doc_id, tf FROM inverted_index WHERE term = ?', (term,))\n",
    "        rows = cursor.fetchall()\n",
    "\n",
    "        for doc_id, tf in rows:\n",
    "            if model_type == 'BIM':\n",
    "                scores[doc_id] = scores.get(doc_id, 0.0) + idf\n",
    "            else: # BM25\n",
    "                doc_len = df.at[doc_id, 'doc_length']\n",
    "                num = tf * (k1 + 1)\n",
    "                den = tf + k1 * (1 - b + b * (doc_len / avg_dl))\n",
    "                scores[doc_id] = scores.get(doc_id, 0.0) + idf * (num / den)\n",
    "    return scores\n",
    "\n",
    "def calculate_metrics(ranked_docs, relevant_docs, k=10):\n",
    "    top_k = ranked_docs[:k]\n",
    "    relevant_retrieved_k = len(set(top_k) & relevant_docs)\n",
    "    p_at_k = relevant_retrieved_k / k\n",
    "\n",
    "    total_relevant = len(relevant_docs)\n",
    "    r_at_k = relevant_retrieved_k / total_relevant if total_relevant > 0 else 0\n",
    "\n",
    "    relevant_count = 0\n",
    "    precision_sum = 0.0\n",
    "    for i, doc_id in enumerate(ranked_docs):\n",
    "        if doc_id in relevant_docs:\n",
    "            relevant_count += 1\n",
    "            precision_sum += relevant_count / (i + 1)\n",
    "\n",
    "    ap = precision_sum / total_relevant if total_relevant > 0 else 0\n",
    "    return p_at_k, r_at_k, ap"
   ],
   "id": "2ee5cc80e6c069bd",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "qrels_dict = {}\n",
    "for item in qrels_data:\n",
    "    qid, doc_id = str(item.get('query-id')), str(item.get('corpus-id'))\n",
    "    if qid and doc_id:\n",
    "        qrels_dict.setdefault(qid, set()).add(doc_id)\n",
    "\n",
    "queries_map = {str(q['_id']): q['text'] for q in queries_data if '_id' in q}\n",
    "\n",
    "print(\"쿼리 전처리\")\n",
    "processed_queries = {}\n",
    "for qid in qrels_dict:\n",
    "    if qid in queries_map:\n",
    "        tokens = tokenize_query(queries_map[qid])\n",
    "        if tokens:\n",
    "            processed_queries[qid] = tokens\n",
    "\n",
    "print(f\"실험 대상 쿼리 수: {len(processed_queries)}\")"
   ],
   "id": "4578397276b9ba45",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"\\n[BM25 하이퍼파라미터 튜닝 (Full Dataset: 정밀 탐색)]\")\n",
    "\n",
    "# 샘플 데이터 최적점(k1=4.0, b=0.98)을 중심으로 집중 탐색\n",
    "k1_values = [3.8, 4.0, 4.2]\n",
    "b_values = [0.95, 0.98, 0.99, 1.0]\n",
    "\n",
    "tuning_results = []\n",
    "best_map = -1\n",
    "# 초기값은 샘플 데이터의 Best 값으로 설정\n",
    "best_params = {'k1': 4.0, 'b': 0.98}\n",
    "\n",
    "print(f\"튜닝 후보: k1={k1_values}, b={b_values} (총 {len(k1_values)*len(b_values)}회 수행)\")\n",
    "\n",
    "for k1_val in k1_values:\n",
    "    for b_val in b_values:\n",
    "        total_map = 0\n",
    "        count = 0\n",
    "\n",
    "        for qid, q_tokens in tqdm(processed_queries.items(), desc=f\"k1={k1_val}, b={b_val}\", leave=False):\n",
    "            if qid not in qrels_dict: continue\n",
    "\n",
    "            scores = calculate_scores(q_tokens, model_type='BM25', k1=k1_val, b=b_val)\n",
    "\n",
    "            ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "            ranked_ids = [d for d, s in ranked[:100]]\n",
    "\n",
    "            _, _, ap = calculate_metrics(ranked_ids, qrels_dict[qid], k=10)\n",
    "            total_map += ap\n",
    "            count += 1\n",
    "\n",
    "        avg_map = total_map / count if count > 0 else 0\n",
    "        print(f\"  - Params(k1={k1_val}, b={b_val}) -> MAP: {avg_map:.4f}\")\n",
    "\n",
    "        tuning_results.append({'k1': k1_val, 'b': b_val, 'MAP': avg_map})\n",
    "\n",
    "        if avg_map > best_map:\n",
    "            best_map = avg_map\n",
    "            best_params = {'k1': k1_val, 'b': b_val}\n",
    "\n",
    "print(f\"\\n최적 파라미터(Full Data): {best_params} (MAP: {best_map:.4f})\")\n",
    "\n",
    "pd.DataFrame(tuning_results).to_csv(os.path.join(DATA_DIR, 'tuning_results_full.csv'), index=False)"
   ],
   "id": "a8371029b787a6b3",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"\\n[최종 평가 및 회귀 데이터셋 생성]\")\n",
    "regression_data = []\n",
    "metrics_data = []\n",
    "\n",
    "models_to_run = [\n",
    "    {'name': 'BIM', 'type': 'BIM', 'k1': 0, 'b': 0},\n",
    "    {'name': 'BM25_Best', 'type': 'BM25', 'k1': best_params['k1'], 'b': best_params['b']}\n",
    "]\n",
    "\n",
    "for model_info in models_to_run:\n",
    "    m_name = model_info['name']\n",
    "    print(f\"  - Running {m_name}\")\n",
    "\n",
    "    for qid, q_tokens in tqdm(processed_queries.items(), desc=m_name):\n",
    "        target_docs = qrels_dict[qid]\n",
    "\n",
    "        scores = calculate_scores(q_tokens, model_type=model_info['type'],\n",
    "                                  k1=model_info['k1'], b=model_info['b'])\n",
    "\n",
    "        ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        ranked_ids = [d for d, s in ranked[:100]]\n",
    "\n",
    "        p10, r10, ap = calculate_metrics(ranked_ids, target_docs, k=10)\n",
    "        metrics_data.append({\n",
    "            'qid': qid,\n",
    "            'model': m_name,\n",
    "            'P@10': p10, 'R@10': r10, 'AP': ap\n",
    "        })\n",
    "\n",
    "        top_10_ids = set(ranked_ids[:10])\n",
    "\n",
    "        for target_doc in target_docs:\n",
    "            if target_doc not in df.index: continue\n",
    "\n",
    "            is_success = 1 if target_doc in top_10_ids else 0\n",
    "            doc_len = df.at[target_doc, 'doc_length']\n",
    "            topic_probs = df.at[target_doc, 'topic_probs']\n",
    "\n",
    "            row = {\n",
    "                'qid': qid,\n",
    "                'doc_id': target_doc,\n",
    "                'model': m_name,\n",
    "                'success': is_success,\n",
    "                'doc_length': doc_len,\n",
    "                'query_length': len(q_tokens),\n",
    "            }\n",
    "            for idx, prob in enumerate(topic_probs):\n",
    "                row[f'topic_{idx}'] = prob\n",
    "\n",
    "            regression_data.append(row)\n",
    "\n",
    "conn.close()"
   ],
   "id": "1c3e9a99fb5572f8",
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_reg = pd.DataFrame(regression_data)\n",
    "df_met = pd.DataFrame(metrics_data)\n",
    "\n",
    "reg_path = os.path.join(DATA_DIR, 'regression_dataset.csv')\n",
    "met_path = os.path.join(DATA_DIR, 'performance_metrics.csv')\n",
    "\n",
    "df_reg.to_csv(reg_path, index=False)\n",
    "df_met.to_csv(met_path, index=False)\n",
    "\n",
    "print(\"\\n[작업 완료]\")\n",
    "print(f\"회귀 데이터셋: {reg_path} ({len(df_reg)}건)\")\n",
    "print(f\"성능 지표: {met_path}\")\n",
    "print(\"\\n[최종 성능 요약]\")\n",
    "print(df_met.groupby('model')[['P@10', 'R@10', 'AP']].mean())"
   ],
   "id": "baa16fcce4aa281b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
