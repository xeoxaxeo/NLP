{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T12:14:48.007767Z",
     "start_time": "2025-12-09T12:14:46.783715Z"
    }
   },
   "source": "!pip install statsmodels pandas numpy tqdm kiwipiepy",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: statsmodels in c:\\users\\cse\\desktop\\xeoxaxeo\\nlp\\.venv\\lib\\site-packages (0.14.6)\n",
      "Requirement already satisfied: pandas in c:\\users\\cse\\desktop\\xeoxaxeo\\nlp\\.venv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\cse\\desktop\\xeoxaxeo\\nlp\\.venv\\lib\\site-packages (2.3.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\cse\\desktop\\xeoxaxeo\\nlp\\.venv\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: kiwipiepy in c:\\users\\cse\\desktop\\xeoxaxeo\\nlp\\.venv\\lib\\site-packages (0.22.1)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in c:\\users\\cse\\desktop\\xeoxaxeo\\nlp\\.venv\\lib\\site-packages (from statsmodels) (1.16.3)\n",
      "Requirement already satisfied: patsy>=0.5.6 in c:\\users\\cse\\desktop\\xeoxaxeo\\nlp\\.venv\\lib\\site-packages (from statsmodels) (1.0.2)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\cse\\desktop\\xeoxaxeo\\nlp\\.venv\\lib\\site-packages (from statsmodels) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\cse\\desktop\\xeoxaxeo\\nlp\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cse\\desktop\\xeoxaxeo\\nlp\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\cse\\desktop\\xeoxaxeo\\nlp\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\cse\\desktop\\xeoxaxeo\\nlp\\.venv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: kiwipiepy_model<0.23,>=0.22 in c:\\users\\cse\\desktop\\xeoxaxeo\\nlp\\.venv\\lib\\site-packages (from kiwipiepy) (0.22.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cse\\desktop\\xeoxaxeo\\nlp\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T12:14:51.372885Z",
     "start_time": "2025-12-09T12:14:48.010468Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import pickle\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from kiwipiepy import Kiwi\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "BASE_DIR = os.path.join('..')\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'final_data')\n",
    "DB_DIR = os.path.join(BASE_DIR, 'final_database')\n",
    "SAMPLE_PATH = os.path.join(DATA_DIR, 'sample.pkl')\n",
    "QUERIES_PATH = os.path.join(BASE_DIR, 'data', 'queries.pkl')\n",
    "QRELS_PATH = os.path.join(BASE_DIR, 'data', 'qrels.pkl')\n",
    "\n",
    "os.makedirs(DB_DIR, exist_ok=True)\n",
    "DB_PATH = os.path.join(DB_DIR, 'search_index_sample.db')\n",
    "\n",
    "print(\"샘플 데이터 로드\")\n",
    "df = pd.read_pickle(SAMPLE_PATH)\n",
    "\n",
    "if '_id' in df.columns:\n",
    "    df.set_index('_id', inplace=True)\n",
    "elif 'doc_id' in df.columns:\n",
    "    df.set_index('doc_id', inplace=True)\n",
    "df.index = df.index.astype(str)\n",
    "\n",
    "with open(QUERIES_PATH, 'rb') as f:\n",
    "    queries_data = pickle.load(f)\n",
    "with open(QRELS_PATH, 'rb') as f:\n",
    "    qrels_data = pickle.load(f)\n",
    "\n",
    "if os.path.exists(DB_PATH):\n",
    "    os.remove(DB_PATH)\n",
    "\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "cursor = conn.cursor()\n",
    "cursor.execute('CREATE TABLE inverted_index (term TEXT, doc_id TEXT, tf INTEGER)')\n",
    "cursor.execute('CREATE INDEX idx_term ON inverted_index(term)')"
   ],
   "id": "674ac063ee82b17f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플 데이터 로드\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x238461bc940>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T12:15:32.169428Z",
     "start_time": "2025-12-09T12:14:51.375974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"역색인 구축 (패딩 제외)\")\n",
    "data_to_insert = []\n",
    "BATCH_SIZE = 10000\n",
    "\n",
    "doc_freq = {}\n",
    "total_docs = len(df)\n",
    "avg_dl = df['doc_length'].mean()\n",
    "\n",
    "for doc_id, row in tqdm(df.iterrows(), total=total_docs, desc=\"Indexing\"):\n",
    "    tokens = row['tokens_padded']\n",
    "    term_counts = {}\n",
    "\n",
    "    for t in tokens:\n",
    "        if set(t) == {'O'}: continue\n",
    "        term_counts[t] = term_counts.get(t, 0) + 1\n",
    "\n",
    "    for term, tf in term_counts.items():\n",
    "        data_to_insert.append((term, str(doc_id), tf))\n",
    "        doc_freq[term] = doc_freq.get(term, 0) + 1\n",
    "\n",
    "    if len(data_to_insert) >= BATCH_SIZE:\n",
    "        cursor.executemany('INSERT INTO inverted_index VALUES (?, ?, ?)', data_to_insert)\n",
    "        data_to_insert = []\n",
    "\n",
    "if data_to_insert:\n",
    "    cursor.executemany('INSERT INTO inverted_index VALUES (?, ?, ?)', data_to_insert)\n",
    "conn.commit()\n",
    "print(\"인덱싱 완료\")"
   ],
   "id": "e4a46e33ff31575",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "역색인 구축 (패딩 제외)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing: 100%|██████████| 5000/5000 [00:40<00:00, 124.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인덱싱 완료\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T12:15:33.094161Z",
     "start_time": "2025-12-09T12:15:32.169428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "kiwi = Kiwi(num_workers=0)\n",
    "idf_cache = {t: math.log((total_docs - df + 0.5) / (df + 0.5) + 1) for t, df in doc_freq.items()}\n",
    "\n",
    "def tokenize_query(text):\n",
    "    try:\n",
    "        return [t.form for t in kiwi.tokenize(text) if t.tag in ['NNG', 'NNP', 'VV', 'VA', 'MAG']]\n",
    "    except: return []\n",
    "\n",
    "def calculate_scores(query_tokens, model_type='BM25', k1=1.2, b=0.75):\n",
    "    scores = {}\n",
    "    for term in query_tokens:\n",
    "        if term not in idf_cache: continue\n",
    "        idf = idf_cache[term]\n",
    "\n",
    "        cursor.execute('SELECT doc_id, tf FROM inverted_index WHERE term = ?', (term,))\n",
    "        rows = cursor.fetchall()\n",
    "\n",
    "        for doc_id, tf in rows:\n",
    "            if model_type == 'BIM':\n",
    "                scores[doc_id] = scores.get(doc_id, 0.0) + idf\n",
    "            else:\n",
    "                doc_len = df.at[doc_id, 'doc_length']\n",
    "                num = tf * (k1 + 1)\n",
    "                den = tf + k1 * (1 - b + b * (doc_len / avg_dl))\n",
    "                scores[doc_id] = scores.get(doc_id, 0.0) + idf * (num / den)\n",
    "    return scores\n",
    "\n",
    "def calculate_metrics(ranked_docs, relevant_docs, k=10):\n",
    "    top_k = ranked_docs[:k]\n",
    "    relevant_retrieved_k = len(set(top_k) & relevant_docs)\n",
    "    p_at_k = relevant_retrieved_k / k\n",
    "\n",
    "    total_relevant = len(relevant_docs)\n",
    "    r_at_k = relevant_retrieved_k / total_relevant if total_relevant > 0 else 0\n",
    "\n",
    "    relevant_count = 0\n",
    "    precision_sum = 0.0\n",
    "    for i, doc_id in enumerate(ranked_docs):\n",
    "        if doc_id in relevant_docs:\n",
    "            relevant_count += 1\n",
    "            precision_sum += relevant_count / (i + 1)\n",
    "\n",
    "    ap = precision_sum / total_relevant if total_relevant > 0 else 0\n",
    "    return p_at_k, r_at_k, ap"
   ],
   "id": "63e94c45714e4071",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T12:15:35.679591Z",
     "start_time": "2025-12-09T12:15:33.099242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "qrels_dict = {}\n",
    "for item in qrels_data:\n",
    "    qid, doc_id = str(item.get('query-id')), str(item.get('corpus-id'))\n",
    "    if qid and doc_id:\n",
    "        qrels_dict.setdefault(qid, set()).add(doc_id)\n",
    "\n",
    "queries_map = {str(q['_id']): q['text'] for q in queries_data if '_id' in q}\n",
    "\n",
    "print(\"쿼리 전처리\")\n",
    "processed_queries = {}\n",
    "for qid in qrels_dict:\n",
    "    if qid in queries_map:\n",
    "        tokens = tokenize_query(queries_map[qid])\n",
    "        if tokens:\n",
    "            processed_queries[qid] = tokens"
   ],
   "id": "1e1efa49961c37a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "쿼리 전처리\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T12:43:50.868310Z",
     "start_time": "2025-12-09T12:29:11.834270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\n[BM25 하이퍼파라미터 튜닝 (Sample)]\")\n",
    "k1_values = [1.0, 1.2, 1.4]\n",
    "b_values = [0.6, 0.75, 0.9]\n",
    "\n",
    "tuning_results = []\n",
    "best_map = -1\n",
    "best_params = {'k1': 1.2, 'b': 0.75}\n",
    "\n",
    "for k1_val in k1_values:\n",
    "    for b_val in b_values:\n",
    "        total_map = 0\n",
    "        count = 0\n",
    "        for qid, q_tokens in processed_queries.items():\n",
    "            if not any(d in df.index for d in qrels_dict[qid]):\n",
    "                continue\n",
    "\n",
    "            scores = calculate_scores(q_tokens, model_type='BM25', k1=k1_val, b=b_val)\n",
    "            ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "            ranked_ids = [d for d, s in ranked[:100]]\n",
    "            _, _, ap = calculate_metrics(ranked_ids, qrels_dict[qid], k=10)\n",
    "            total_map += ap\n",
    "            count += 1\n",
    "\n",
    "        avg_map = total_map / count if count > 0 else 0\n",
    "        print(f\"  - Params(k1={k1_val}, b={b_val}) -> MAP: {avg_map:.4f}\")\n",
    "        tuning_results.append({'k1': k1_val, 'b': b_val, 'MAP': avg_map})\n",
    "\n",
    "        if avg_map > best_map:\n",
    "            best_map = avg_map\n",
    "            best_params = {'k1': k1_val, 'b': b_val}\n",
    "\n",
    "print(f\"Best: {best_params} (MAP: {best_map:.4f})\")\n",
    "pd.DataFrame(tuning_results).to_csv(os.path.join(DATA_DIR, 'tuning_results_sample.csv'), index=False)\n"
   ],
   "id": "5a455f75b5a7d9c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[BM25 하이퍼파라미터 튜닝 (Sample)]\n",
      "  - Params(k1=1.0, b=0.6) -> MAP: 0.5772\n",
      "  - Params(k1=1.0, b=0.75) -> MAP: 0.5938\n",
      "  - Params(k1=1.0, b=0.9) -> MAP: 0.6070\n",
      "  - Params(k1=1.2, b=0.6) -> MAP: 0.5839\n",
      "  - Params(k1=1.2, b=0.75) -> MAP: 0.6004\n",
      "  - Params(k1=1.2, b=0.9) -> MAP: 0.6145\n",
      "  - Params(k1=1.4, b=0.6) -> MAP: 0.5884\n",
      "  - Params(k1=1.4, b=0.75) -> MAP: 0.6052\n",
      "  - Params(k1=1.4, b=0.9) -> MAP: 0.6180\n",
      "Best: {'k1': 1.4, 'b': 0.9} (MAP: 0.6180)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T13:22:21.801488Z",
     "start_time": "2025-12-09T12:47:24.810922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\n[BM25 하이퍼파라미터 튜닝 (2차: 범위 확장)]\")\n",
    "\n",
    "k1_values = [1.4, 1.5, 1.6, 1.8, 2.0]\n",
    "b_values = [0.8, 0.9, 0.95, 1.0]\n",
    "\n",
    "tuning_results = []\n",
    "best_map = -1\n",
    "best_params = {'k1': 1.4, 'b': 0.9} # 1차 튜닝 최고점\n",
    "\n",
    "for k1_val in k1_values:\n",
    "    for b_val in b_values:\n",
    "        total_map = 0\n",
    "        count = 0\n",
    "        for qid, q_tokens in processed_queries.items():\n",
    "            if not any(d in df.index for d in qrels_dict[qid]):\n",
    "                continue\n",
    "\n",
    "            scores = calculate_scores(q_tokens, model_type='BM25', k1=k1_val, b=b_val)\n",
    "\n",
    "            ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "            ranked_ids = [d for d, s in ranked[:100]]\n",
    "\n",
    "            _, _, ap = calculate_metrics(ranked_ids, qrels_dict[qid], k=10)\n",
    "            total_map += ap\n",
    "            count += 1\n",
    "\n",
    "        avg_map = total_map / count if count > 0 else 0\n",
    "        print(f\"  - Params(k1={k1_val}, b={b_val}) -> MAP: {avg_map:.4f}\")\n",
    "        tuning_results.append({'k1': k1_val, 'b': b_val, 'MAP': avg_map})\n",
    "\n",
    "        if avg_map > best_map:\n",
    "            best_map = avg_map\n",
    "            best_params = {'k1': k1_val, 'b': b_val}\n",
    "\n",
    "print(f\"\\nBest: {best_params} (MAP: {best_map:.4f})\")\n",
    "pd.DataFrame(tuning_results).to_csv(os.path.join(DATA_DIR, 'tuning_results_sample.csv'), index=False)"
   ],
   "id": "6fa717183633f15",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[BM25 하이퍼파라미터 튜닝 (2차: 범위 확장)]\n",
      "  - Params(k1=1.4, b=0.8) -> MAP: 0.6102\n",
      "  - Params(k1=1.4, b=0.9) -> MAP: 0.6180\n",
      "  - Params(k1=1.4, b=0.95) -> MAP: 0.6217\n",
      "  - Params(k1=1.4, b=1.0) -> MAP: 0.6230\n",
      "  - Params(k1=1.5, b=0.8) -> MAP: 0.6121\n",
      "  - Params(k1=1.5, b=0.9) -> MAP: 0.6206\n",
      "  - Params(k1=1.5, b=0.95) -> MAP: 0.6235\n",
      "  - Params(k1=1.5, b=1.0) -> MAP: 0.6249\n",
      "  - Params(k1=1.6, b=0.8) -> MAP: 0.6133\n",
      "  - Params(k1=1.6, b=0.9) -> MAP: 0.6221\n",
      "  - Params(k1=1.6, b=0.95) -> MAP: 0.6249\n",
      "  - Params(k1=1.6, b=1.0) -> MAP: 0.6262\n",
      "  - Params(k1=1.8, b=0.8) -> MAP: 0.6160\n",
      "  - Params(k1=1.8, b=0.9) -> MAP: 0.6254\n",
      "  - Params(k1=1.8, b=0.95) -> MAP: 0.6280\n",
      "  - Params(k1=1.8, b=1.0) -> MAP: 0.6293\n",
      "  - Params(k1=2.0, b=0.8) -> MAP: 0.6181\n",
      "  - Params(k1=2.0, b=0.9) -> MAP: 0.6276\n",
      "  - Params(k1=2.0, b=0.95) -> MAP: 0.6300\n",
      "  - Params(k1=2.0, b=1.0) -> MAP: 0.6325\n",
      "\n",
      "Best: {'k1': 2.0, 'b': 1.0} (MAP: 0.6325)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T13:48:56.207184Z",
     "start_time": "2025-12-09T13:33:21.021998Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\n[BM25 하이퍼파라미터 튜닝 (3차)]\")\n",
    "\n",
    "k1_values = [2.0, 4.0, 6.0]\n",
    "b_values = [1.0, 2.0, 3.0]\n",
    "\n",
    "tuning_results = []\n",
    "best_map = -1\n",
    "best_params = {'k1': 2.0, 'b': 1.0} # 2차 튜닝 최고점\n",
    "\n",
    "for k1_val in k1_values:\n",
    "    for b_val in b_values:\n",
    "        total_map = 0\n",
    "        count = 0\n",
    "        for qid, q_tokens in processed_queries.items():\n",
    "            if not any(d in df.index for d in qrels_dict[qid]):\n",
    "                continue\n",
    "\n",
    "            scores = calculate_scores(q_tokens, model_type='BM25', k1=k1_val, b=b_val)\n",
    "\n",
    "            ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "            ranked_ids = [d for d, s in ranked[:100]]\n",
    "\n",
    "            _, _, ap = calculate_metrics(ranked_ids, qrels_dict[qid], k=10)\n",
    "            total_map += ap\n",
    "            count += 1\n",
    "\n",
    "        avg_map = total_map / count if count > 0 else 0\n",
    "        print(f\"  - Params(k1={k1_val}, b={b_val}) -> MAP: {avg_map:.4f}\")\n",
    "        tuning_results.append({'k1': k1_val, 'b': b_val, 'MAP': avg_map})\n",
    "\n",
    "        if avg_map > best_map:\n",
    "            best_map = avg_map\n",
    "            best_params = {'k1': k1_val, 'b': b_val}\n",
    "\n",
    "print(f\"\\nBest: {best_params} (MAP: {best_map:.4f})\")\n",
    "pd.DataFrame(tuning_results).to_csv(os.path.join(DATA_DIR, 'tuning_results_sample.csv'), index=False)"
   ],
   "id": "c93cddf18c7e0738",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[BM25 하이퍼파라미터 튜닝 (3차)]\n",
      "  - Params(k1=2.0, b=1.0) -> MAP: 0.6325\n",
      "  - Params(k1=2.0, b=2.0) -> MAP: 0.0419\n",
      "  - Params(k1=2.0, b=3.0) -> MAP: 0.0282\n",
      "  - Params(k1=4.0, b=1.0) -> MAP: 0.6378\n",
      "  - Params(k1=4.0, b=2.0) -> MAP: 0.0377\n",
      "  - Params(k1=4.0, b=3.0) -> MAP: 0.0326\n",
      "  - Params(k1=6.0, b=1.0) -> MAP: 0.6354\n",
      "  - Params(k1=6.0, b=2.0) -> MAP: 0.0337\n",
      "  - Params(k1=6.0, b=3.0) -> MAP: 0.0348\n",
      "\n",
      "Best: {'k1': 4.0, 'b': 1.0} (MAP: 0.6378)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T14:45:40.068290Z",
     "start_time": "2025-12-09T14:00:24.788903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\n[BM25 하이퍼파라미터 튜닝 (4차)]\")\n",
    "\n",
    "k1_values = [3.0, 3.5, 3.8, 4.0, 4.2, 4.5, 5.0]\n",
    "b_values = [0.95, 0.98, 0.99, 1.0]\n",
    "\n",
    "tuning_results = []\n",
    "best_map = -1\n",
    "best_params = {'k1': 4.0, 'b': 1.0}\n",
    "\n",
    "for k1_val in k1_values:\n",
    "    for b_val in b_values:\n",
    "        total_map = 0\n",
    "        count = 0\n",
    "        for qid, q_tokens in processed_queries.items():\n",
    "            if not any(d in df.index for d in qrels_dict[qid]):\n",
    "                continue\n",
    "\n",
    "            scores = calculate_scores(q_tokens, model_type='BM25', k1=k1_val, b=b_val)\n",
    "\n",
    "            ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "            ranked_ids = [d for d, s in ranked[:100]]\n",
    "\n",
    "            _, _, ap = calculate_metrics(ranked_ids, qrels_dict[qid], k=10)\n",
    "            total_map += ap\n",
    "            count += 1\n",
    "\n",
    "        avg_map = total_map / count if count > 0 else 0\n",
    "        print(f\"  - Params(k1={k1_val}, b={b_val}) -> MAP: {avg_map:.4f}\")\n",
    "        tuning_results.append({'k1': k1_val, 'b': b_val, 'MAP': avg_map})\n",
    "\n",
    "        if avg_map > best_map:\n",
    "            best_map = avg_map\n",
    "            best_params = {'k1': k1_val, 'b': b_val}\n",
    "\n",
    "print(f\"\\nFinal Best: {best_params} (MAP: {best_map:.4f})\")\n",
    "pd.DataFrame(tuning_results).to_csv(os.path.join(DATA_DIR, 'tuning_results_sample.csv'), index=False)"
   ],
   "id": "ada5a6714ea88dc8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[BM25 하이퍼파라미터 튜닝 (4차)]\n",
      "  - Params(k1=3.0, b=0.95) -> MAP: 0.6365\n",
      "  - Params(k1=3.0, b=0.98) -> MAP: 0.6375\n",
      "  - Params(k1=3.0, b=0.99) -> MAP: 0.6374\n",
      "  - Params(k1=3.0, b=1.0) -> MAP: 0.6374\n",
      "  - Params(k1=3.5, b=0.95) -> MAP: 0.6377\n",
      "  - Params(k1=3.5, b=0.98) -> MAP: 0.6377\n",
      "  - Params(k1=3.5, b=0.99) -> MAP: 0.6382\n",
      "  - Params(k1=3.5, b=1.0) -> MAP: 0.6375\n",
      "  - Params(k1=3.8, b=0.95) -> MAP: 0.6379\n",
      "  - Params(k1=3.8, b=0.98) -> MAP: 0.6379\n",
      "  - Params(k1=3.8, b=0.99) -> MAP: 0.6385\n",
      "  - Params(k1=3.8, b=1.0) -> MAP: 0.6379\n",
      "  - Params(k1=4.0, b=0.95) -> MAP: 0.6381\n",
      "  - Params(k1=4.0, b=0.98) -> MAP: 0.6389\n",
      "  - Params(k1=4.0, b=0.99) -> MAP: 0.6386\n",
      "  - Params(k1=4.0, b=1.0) -> MAP: 0.6378\n",
      "  - Params(k1=4.2, b=0.95) -> MAP: 0.6388\n",
      "  - Params(k1=4.2, b=0.98) -> MAP: 0.6388\n",
      "  - Params(k1=4.2, b=0.99) -> MAP: 0.6388\n",
      "  - Params(k1=4.2, b=1.0) -> MAP: 0.6377\n",
      "  - Params(k1=4.5, b=0.95) -> MAP: 0.6384\n",
      "  - Params(k1=4.5, b=0.98) -> MAP: 0.6385\n",
      "  - Params(k1=4.5, b=0.99) -> MAP: 0.6381\n",
      "  - Params(k1=4.5, b=1.0) -> MAP: 0.6374\n",
      "  - Params(k1=5.0, b=0.95) -> MAP: 0.6379\n",
      "  - Params(k1=5.0, b=0.98) -> MAP: 0.6383\n",
      "  - Params(k1=5.0, b=0.99) -> MAP: 0.6374\n",
      "  - Params(k1=5.0, b=1.0) -> MAP: 0.6366\n",
      "\n",
      "Final Best: {'k1': 4.0, 'b': 0.98} (MAP: 0.6389)\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T14:48:18.840846Z",
     "start_time": "2025-12-09T14:45:40.107905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"\\n[회귀 데이터 생성 (Sample)]\")\n",
    "regression_data = []\n",
    "metrics_data = []\n",
    "\n",
    "models_to_run = [\n",
    "    {'name': 'BIM', 'type': 'BIM', 'k1': 0, 'b': 0},\n",
    "    {'name': 'BM25_Best', 'type': 'BM25', 'k1': best_params['k1'], 'b': best_params['b']}\n",
    "]\n",
    "\n",
    "for model_info in models_to_run:\n",
    "    m_name = model_info['name']\n",
    "    for qid, q_tokens in tqdm(processed_queries.items(), desc=m_name):\n",
    "        target_docs = qrels_dict[qid]\n",
    "        valid_targets = [d for d in target_docs if d in df.index]\n",
    "        if not valid_targets: continue\n",
    "\n",
    "        scores = calculate_scores(q_tokens, model_type=model_info['type'],\n",
    "                                  k1=model_info['k1'], b=model_info['b'])\n",
    "\n",
    "        ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        ranked_ids = [d for d, s in ranked[:100]]\n",
    "\n",
    "        p10, r10, ap = calculate_metrics(ranked_ids, target_docs, k=10)\n",
    "        metrics_data.append({'qid': qid, 'model': m_name, 'P@10': p10, 'R@10': r10, 'AP': ap})\n",
    "\n",
    "        top_10_ids = set(ranked_ids[:10])\n",
    "\n",
    "        for target_doc in valid_targets:\n",
    "            is_success = 1 if target_doc in top_10_ids else 0\n",
    "            doc_len = df.at[target_doc, 'doc_length']\n",
    "            topic_probs = df.at[target_doc, 'topic_probs']\n",
    "\n",
    "            row = {\n",
    "                'qid': qid, 'doc_id': target_doc, 'model': m_name,\n",
    "                'success': is_success, 'doc_length': doc_len,\n",
    "                'query_length': len(q_tokens),\n",
    "            }\n",
    "            for idx, prob in enumerate(topic_probs):\n",
    "                row[f'topic_{idx}'] = prob\n",
    "            regression_data.append(row)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "df_reg = pd.DataFrame(regression_data)\n",
    "df_met = pd.DataFrame(metrics_data)\n",
    "\n",
    "reg_path = os.path.join(DATA_DIR, 'regression_dataset_sample.csv')\n",
    "met_path = os.path.join(DATA_DIR, 'performance_metrics_sample.csv')\n",
    "\n",
    "df_reg.to_csv(reg_path, index=False)\n",
    "df_met.to_csv(met_path, index=False)\n",
    "\n",
    "print(\"\\n[샘플링 작업 완료]\")\n",
    "print(f\"회귀 데이터: {reg_path}\")\n",
    "print(f\"성능 지표: {met_path}\")"
   ],
   "id": "4073679a79bde1a3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[회귀 데이터 생성 (Sample)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BIM: 100%|██████████| 1454/1454 [01:03<00:00, 22.80it/s]\n",
      "BM25_Best: 100%|██████████| 1454/1454 [01:34<00:00, 15.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[샘플링 작업 완료]\n",
      "회귀 데이터: ..\\final_data\\regression_dataset_sample.csv\n",
      "성능 지표: ..\\final_data\\performance_metrics_sample.csv\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
