{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T10:15:00.752812Z",
     "start_time": "2025-12-09T10:14:58.203960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from kiwipiepy import Kiwi\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "CORPUS_PATH = os.path.join('..', 'data', 'corpus.pkl')\n",
    "QRELS_PATH = os.path.join('..', 'data', 'qrels.pkl')\n",
    "DATA_DIR = os.path.join('..', 'final_data')\n",
    "\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "print(\"데이터 로드 (Corpus + Qrels)\")\n",
    "with open(CORPUS_PATH, 'rb') as f:\n",
    "    corpus_data = pickle.load(f)\n",
    "with open(QRELS_PATH, 'rb') as f:\n",
    "    qrels_data = pickle.load(f)\n",
    "\n",
    "df = pd.DataFrame(corpus_data)\n",
    "if 'text' not in df.columns and 'body' in df.columns:\n",
    "    df.rename(columns={'body': 'text'}, inplace=True)"
   ],
   "id": "9c0a2fbcd3487afc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로드 (Corpus + Qrels)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T10:15:56.199526Z",
     "start_time": "2025-12-09T10:15:56.195529Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"데이터 타입: {type(qrels_data)}\")\n",
    "if isinstance(qrels_data, list) and len(qrels_data) > 0:\n",
    "    print(f\"첫 번째 데이터 샘플: {qrels_data[0]}\")\n",
    "    print(f\"데이터 길이: {len(qrels_data)}\")\n",
    "else:\n",
    "    print(\"오류\")"
   ],
   "id": "1db31d40a2c2415c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 타입: <class 'list'>\n",
      "첫 번째 데이터 샘플: {'query-id': 'query_000001', 'corpus-id': '부머(폴아웃: 뉴 베가스)', 'score': 1}\n",
      "데이터 길이: 6289\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T10:18:36.061214Z",
     "start_time": "2025-12-09T10:18:36.031858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Smart Sampling 수행 (정답 문서 보존)\")\n",
    "relevant_doc_ids = set()\n",
    "for item in qrels_data:\n",
    "    if 'corpus-id' in item:\n",
    "        relevant_doc_ids.add(item['corpus-id'])\n",
    "\n",
    "id_col = '_id' if '_id' in df.columns else 'doc_id'\n",
    "print(f\"매칭 기준 컬럼: {id_col}\")\n",
    "\n",
    "df_relevant = df[df[id_col].isin(relevant_doc_ids)]\n",
    "df_others = df[~df[id_col].isin(relevant_doc_ids)]\n",
    "\n",
    "print(f\"  - 정답 문서 수: {len(df_relevant)}개 (필수 포함)\")\n",
    "\n",
    "target_n = 5000\n",
    "needed_n = target_n - len(df_relevant)\n",
    "\n",
    "if needed_n > 0:\n",
    "    df_random = df_others.sample(n=needed_n, random_state=42)\n",
    "    df_sample = pd.concat([df_relevant, df_random])\n",
    "else:\n",
    "    df_sample = df_relevant.sample(n=target_n, random_state=42)\n",
    "\n",
    "df_sample = df_sample.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(f\"  - 최종 샘플링 완료: {len(df_sample)}개\")"
   ],
   "id": "48e5691f5dc736dc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smart Sampling 수행 (정답 문서 보존)\n",
      "매칭 기준 컬럼: _id\n",
      "  - 정답 문서 수: 6194개 (필수 포함)\n",
      "  - 최종 샘플링 완료: 5000개\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T10:34:56.715385Z",
     "start_time": "2025-12-09T10:20:19.098413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "kiwi = Kiwi(num_workers=0)\n",
    "\n",
    "def preprocess_dual(text):\n",
    "    if not isinstance(text, str):\n",
    "        return [], []\n",
    "\n",
    "    try:\n",
    "        tokens = kiwi.tokenize(text)\n",
    "        padded = []\n",
    "        meaningful = []\n",
    "        target_pos = ['NNG', 'NNP', 'VV', 'VA', 'MAG']\n",
    "\n",
    "        for t in tokens:\n",
    "            if t.tag in target_pos:\n",
    "                if len(t.form) > 1:\n",
    "                    padded.append(t.form)\n",
    "                    meaningful.append(t.form)\n",
    "                else:\n",
    "                    padded.append('O' * len(t.form))\n",
    "            else:\n",
    "                padded.append('O' * len(t.form))\n",
    "\n",
    "        return padded, meaningful\n",
    "    except:\n",
    "        return [], []\n",
    "\n",
    "tqdm.pandas()\n",
    "print(\"데이터 전처리 (Length Preserving Padding + LDA)\")\n",
    "df_sample[['tokens_padded', 'tokens_lda']] = df_sample['text'].progress_apply(\n",
    "    lambda x: pd.Series(preprocess_dual(x))\n",
    ")\n",
    "\n",
    "df_sample['doc_length'] = df_sample['tokens_padded'].apply(lambda x: sum(len(t) for t in x))"
   ],
   "id": "4942b69ac4aa7fcd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 전처리 (Length Preserving Padding + LDA)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [14:36<00:00,  5.71it/s]  \n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T10:35:47.144151Z",
     "start_time": "2025-12-09T10:34:56.737584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"LDA 토픽 모델 학습\")\n",
    "lda_tokens = df_sample['tokens_lda'].tolist()\n",
    "dictionary = corpora.Dictionary(lda_tokens)\n",
    "dictionary.filter_extremes(no_below=10, no_above=0.5)\n",
    "corpus = [dictionary.doc2bow(text) for text in lda_tokens]\n",
    "\n",
    "lda_model = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=dictionary,\n",
    "    num_topics=10,\n",
    "    random_state=42,\n",
    "    passes=10,\n",
    "    alpha='auto',\n",
    "    per_word_topics=True\n",
    ")\n",
    "\n",
    "def get_topic_probs(tokens):\n",
    "    if not tokens:\n",
    "        return [0.1] * 10\n",
    "    bow = dictionary.doc2bow(tokens)\n",
    "    topics = lda_model.get_document_topics(bow, minimum_probability=0.0)\n",
    "    topic_vec = [0.0] * 10\n",
    "    for topic_id, prob in topics:\n",
    "        topic_vec[topic_id] = prob\n",
    "    return topic_vec\n",
    "\n",
    "print(\"토픽 확률 추론\")\n",
    "df_sample['topic_probs'] = df_sample['tokens_lda'].progress_apply(get_topic_probs)\n",
    "\n",
    "sample_save_path = os.path.join(DATA_DIR, 'sample.pkl')\n",
    "model_save_path = os.path.join(DATA_DIR, 'lda.model')\n",
    "\n",
    "df_sample.to_pickle(sample_save_path)\n",
    "lda_model.save(model_save_path)\n",
    "\n",
    "print(\"작업 완료\")\n",
    "print(f\"저장 경로: {DATA_DIR}\")\n",
    "\n",
    "print(\"\\n[Padding 결과 예시]\")\n",
    "print(f\"Original Text snippet: {df_sample['text'].iloc[0][:30]}...\")\n",
    "print(f\"Padded Tokens: {df_sample['tokens_padded'].iloc[0][:10]}\")\n",
    "\n",
    "print(\"\\n[LDA 토픽 목록]\")\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(f\"Topic {idx}: {topic}\")"
   ],
   "id": "de93b295e71dfe69",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA 토픽 모델 학습\n",
      "토픽 확률 추론\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:03<00:00, 1282.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "작업 완료\n",
      "저장 경로: ..\\final_data\n",
      "\n",
      "[Padding 결과 예시]\n",
      "Original Text snippet: 야인시대 합성물(심영물)에 등장하는 인물과 그 인물의 ...\n",
      "Padded Tokens: ['야인시대', '합성', 'O', 'O', 'O', '영물', 'O', 'O', '등장', 'O']\n",
      "\n",
      "[LDA 토픽 목록]\n",
      "Topic 0: 0.006*\"지역\" + 0.005*\"대통령\" + 0.005*\"사건\" + 0.005*\"정부\" + 0.004*\"서울\" + 0.004*\"국가\" + 0.004*\"학교\" + 0.004*\"대학\" + 0.003*\"선거\" + 0.003*\"의원\"\n",
      "Topic 1: 0.011*\"방송\" + 0.007*\"멤버\" + 0.006*\"영상\" + 0.006*\"출연\" + 0.005*\"활동\" + 0.005*\"노래\" + 0.005*\"코너\" + 0.005*\"부르\" + 0.004*\"영화\" + 0.004*\"앨범\"\n",
      "Topic 2: 0.012*\"조선\" + 0.006*\"고려\" + 0.005*\"일본\" + 0.005*\"기록\" + 0.004*\"황제\" + 0.004*\"신라\" + 0.004*\"시대\" + 0.004*\"인물\" + 0.004*\"고구려\" + 0.004*\"조조\"\n",
      "Topic 3: 0.015*\"공격\" + 0.011*\"스킬\" + 0.009*\"레벨\" + 0.008*\"효과\" + 0.007*\"카드\" + 0.006*\"증가\" + 0.006*\"마법\" + 0.005*\"추가\" + 0.005*\"데미지\" + 0.005*\"상대\"\n",
      "Topic 4: 0.023*\"경기\" + 0.017*\"시즌\" + 0.015*\"선수\" + 0.011*\"리그\" + 0.010*\"우승\" + 0.008*\"기록\" + 0.007*\"감독\" + 0.005*\"상대\" + 0.005*\"승리\" + 0.005*\"진출\"\n",
      "Topic 5: 0.004*\"인간\" + 0.004*\"캐릭터\" + 0.003*\"주인공\" + 0.003*\"죽이\" + 0.003*\"장면\" + 0.003*\"모르\" + 0.003*\"능력\" + 0.003*\"당하\" + 0.003*\"아버지\" + 0.003*\"만나\"\n",
      "Topic 6: 0.023*\"게임\" + 0.008*\"시리즈\" + 0.008*\"버스\" + 0.005*\"추가\" + 0.004*\"모드\" + 0.004*\"차량\" + 0.004*\"디자인\" + 0.004*\"출시\" + 0.004*\"노선\" + 0.004*\"소닉\"\n",
      "Topic 7: 0.012*\"전쟁\" + 0.009*\"국가\" + 0.008*\"제국\" + 0.007*\"미국\" + 0.006*\"러시아\" + 0.005*\"영국\" + 0.005*\"지역\" + 0.005*\"세계\" + 0.005*\"도시\" + 0.004*\"시대\"\n",
      "Topic 8: 0.009*\"무기\" + 0.007*\"기술\" + 0.006*\"포켓몬\" + 0.005*\"공격\" + 0.005*\"세대\" + 0.004*\"상대\" + 0.004*\"총기\" + 0.004*\"성능\" + 0.004*\"속도\" + 0.004*\"빠르\"\n",
      "Topic 9: 0.007*\"한국\" + 0.005*\"일본\" + 0.004*\"의미\" + 0.004*\"주장\" + 0.004*\"중국\" + 0.004*\"사회\" + 0.004*\"표현\" + 0.003*\"쓰이\" + 0.003*\"표기\" + 0.003*\"게임\"\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
