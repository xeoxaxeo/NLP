{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T11:50:09.381379Z",
     "start_time": "2025-12-09T11:50:07.870894Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\cse\\desktop\\xeoxaxeo\\nlp\\.venv\\lib\\site-packages (4.4.0)\n",
      "Requirement already satisfied: kiwipiepy in c:\\users\\cse\\desktop\\xeoxaxeo\\nlp\\.venv\\lib\\site-packages (0.22.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\cse\\desktop\\xeoxaxeo\\nlp\\.venv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\cse\\desktop\\xeoxaxeo\\nlp\\.venv\\lib\\site-packages (2.3.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\cse\\desktop\\xeoxaxeo\\nlp\\.venv\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\cse\\desktop\\xeoxaxeo\\nlp\\.venv\\lib\\site-packages (from gensim) (1.16.3)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in c:\\users\\cse\\desktop\\xeoxaxeo\\nlp\\.venv\\lib\\site-packages (from gensim) (7.5.0)\n",
      "Requirement already satisfied: kiwipiepy_model<0.23,>=0.22 in c:\\users\\cse\\desktop\\xeoxaxeo\\nlp\\.venv\\lib\\site-packages (from kiwipiepy) (0.22.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\cse\\desktop\\xeoxaxeo\\nlp\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cse\\desktop\\xeoxaxeo\\nlp\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\cse\\desktop\\xeoxaxeo\\nlp\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\cse\\desktop\\xeoxaxeo\\nlp\\.venv\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cse\\desktop\\xeoxaxeo\\nlp\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\cse\\desktop\\xeoxaxeo\\nlp\\.venv\\lib\\site-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim kiwipiepy pandas numpy tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3253186864fc57d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T11:50:11.951039Z",
     "start_time": "2025-12-09T11:50:09.398076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로드\n",
      "전체 문서 수: 50222개\n",
      "스마트 샘플링 수행\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from kiwipiepy import Kiwi\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 경로 설정\n",
    "BASE_DIR = os.path.join('..')\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'final_data')\n",
    "CORPUS_PATH = os.path.join(BASE_DIR, 'data', 'corpus.pkl')\n",
    "QRELS_PATH = os.path.join(BASE_DIR, 'data', 'qrels.pkl')\n",
    "\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "print(\"데이터 로드\")\n",
    "with open(CORPUS_PATH, 'rb') as f:\n",
    "    corpus_data = pickle.load(f)\n",
    "with open(QRELS_PATH, 'rb') as f:\n",
    "    qrels_data = pickle.load(f)\n",
    "\n",
    "df = pd.DataFrame(corpus_data)\n",
    "if 'text' not in df.columns and 'body' in df.columns:\n",
    "    df.rename(columns={'body': 'text'}, inplace=True)\n",
    "\n",
    "\n",
    "id_col = '_id' if '_id' in df.columns else 'doc_id'\n",
    "\n",
    "\n",
    "print(f\"전체 문서 수: {len(df)}개\")\n",
    "print(\"스마트 샘플링 수행\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca2fc41d642f0957",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T11:50:11.990433Z",
     "start_time": "2025-12-09T11:50:11.956552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 필수 포함(정답) 문서: 6194개\n",
      " - 최종 샘플링 완료: 5000개\n"
     ]
    }
   ],
   "source": [
    "# 정답 문서 ID 추출\n",
    "relevant_ids = set()\n",
    "for item in qrels_data:\n",
    "    if 'corpus-id' in item:\n",
    "        relevant_ids.add(item['corpus-id'])\n",
    "\n",
    "# 데이터 분리\n",
    "df_relevant = df[df[id_col].isin(relevant_ids)]\n",
    "df_others = df[~df[id_col].isin(relevant_ids)]\n",
    "\n",
    "print(f\" - 필수 포함(정답) 문서: {len(df_relevant)}개\")\n",
    "\n",
    "TARGET_N = 5000\n",
    "needed_n = TARGET_N - len(df_relevant)\n",
    "\n",
    "if needed_n > 0:\n",
    "    df_random = df_others.sample(n=needed_n, random_state=42)\n",
    "    df_sample = pd.concat([df_relevant, df_random])\n",
    "else:\n",
    "    df_sample = df_relevant.sample(n=TARGET_N, random_state=42)\n",
    "\n",
    "df = df_sample.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(f\" - 최종 샘플링 완료: {len(df)}개\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70463a10d7b08b03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T12:07:42.435360Z",
     "start_time": "2025-12-09T11:50:12.003447Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 수행 (Padding + LDA 토큰)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [17:28<00:00,  4.77it/s]  \n"
     ]
    }
   ],
   "source": [
    "# 전처리 및 LDA\n",
    "\n",
    "kiwi = Kiwi(num_workers=0)\n",
    "\n",
    "def preprocess_dual(text):\n",
    "    if not isinstance(text, str):\n",
    "        return [], []\n",
    "\n",
    "    try:\n",
    "        tokens = kiwi.tokenize(text)\n",
    "        padded = []\n",
    "        meaningful = []\n",
    "        target_pos = ['NNG', 'NNP', 'VV', 'VA', 'MAG']\n",
    "\n",
    "        for t in tokens:\n",
    "            if t.tag in target_pos:\n",
    "                if len(t.form) > 1:\n",
    "                    padded.append(t.form)\n",
    "                    meaningful.append(t.form)\n",
    "                else:\n",
    "                    padded.append('O' * len(t.form))\n",
    "            else:\n",
    "                padded.append('O' * len(t.form))\n",
    "        return padded, meaningful\n",
    "    except:\n",
    "        return [], []\n",
    "\n",
    "tqdm.pandas()\n",
    "print(\"전처리 수행 (Padding + LDA 토큰)\")\n",
    "df[['tokens_padded', 'tokens_lda']] = df['text'].progress_apply(\n",
    "    lambda x: pd.Series(preprocess_dual(x))\n",
    ")\n",
    "\n",
    "df['doc_length'] = df['tokens_padded'].apply(lambda x: sum(len(t) for t in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "224fcde6413c7969",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T12:11:27.544838Z",
     "start_time": "2025-12-09T12:09:19.283072Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA 모델 학습\n",
      "토픽 확률 추출\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:04<00:00, 1082.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "작업 완료\n",
      "샘플 데이터 저장: ..\\final_data\\sample.pkl\n"
     ]
    }
   ],
   "source": [
    "print(\"LDA 모델 학습\")\n",
    "lda_tokens = df['tokens_lda'].tolist()\n",
    "dictionary = corpora.Dictionary(lda_tokens)\n",
    "dictionary.filter_extremes(no_below=10, no_above=0.5)\n",
    "corpus = [dictionary.doc2bow(text) for text in lda_tokens]\n",
    "\n",
    "lda_model = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=dictionary,\n",
    "    num_topics=10,\n",
    "    random_state=42,\n",
    "    passes=10,\n",
    "    alpha='auto'\n",
    ")\n",
    "\n",
    "def get_topic_probs(tokens):\n",
    "    if not tokens:\n",
    "        return [0.1] * 10\n",
    "    bow = dictionary.doc2bow(tokens)\n",
    "    topics = lda_model.get_document_topics(bow, minimum_probability=0.0)\n",
    "    topic_vec = [0.0] * 10\n",
    "    for topic_id, prob in topics:\n",
    "        topic_vec[topic_id] = prob\n",
    "    return topic_vec\n",
    "\n",
    "print(\"토픽 확률 추출\")\n",
    "df['topic_probs'] = df['tokens_lda'].progress_apply(get_topic_probs)\n",
    "\n",
    "save_path = os.path.join(DATA_DIR, 'sample.pkl')\n",
    "model_path = os.path.join(DATA_DIR, 'lda_sample.model')\n",
    "\n",
    "df.to_pickle(save_path)\n",
    "lda_model.save(model_path)\n",
    "\n",
    "print(\"작업 완료\")\n",
    "print(f\"샘플 데이터 저장: {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
