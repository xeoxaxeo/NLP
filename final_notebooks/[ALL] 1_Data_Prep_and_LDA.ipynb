{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T11:32:16.214650Z",
     "start_time": "2025-12-09T11:32:12.947445Z"
    }
   },
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from kiwipiepy import Kiwi\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 경로 설정\n",
    "BASE_DIR = os.path.join('..')\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'final_data')\n",
    "CORPUS_PATH = os.path.join(BASE_DIR, 'data', 'corpus.pkl')\n",
    "\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "print(\"전체 데이터 로드\")\n",
    "with open(CORPUS_PATH, 'rb') as f:\n",
    "    corpus_data = pickle.load(f)\n",
    "\n",
    "df = pd.DataFrame(corpus_data)\n",
    "if 'text' not in df.columns and 'body' in df.columns:\n",
    "    df.rename(columns={'body': 'text'}, inplace=True)\n",
    "\n",
    "# 전체 데이터 사용 (샘플링 X)\n",
    "print(f\"전체 문서 수: {len(df)}개\")\n",
    "\n",
    "kiwi = Kiwi(num_workers=0)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 데이터 로드\n",
      "전체 문서 수: 50222개\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T13:39:53.565558Z",
     "start_time": "2025-12-09T11:32:16.222633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_dual(text):\n",
    "    if not isinstance(text, str):\n",
    "        return [], []\n",
    "\n",
    "    try:\n",
    "        tokens = kiwi.tokenize(text)\n",
    "        padded = []\n",
    "        meaningful = []\n",
    "        target_pos = ['NNG', 'NNP', 'VV', 'VA', 'MAG']\n",
    "\n",
    "        for t in tokens:\n",
    "            if t.tag in target_pos:\n",
    "                if len(t.form) > 1:\n",
    "                    padded.append(t.form)\n",
    "                    meaningful.append(t.form)\n",
    "                else:\n",
    "                    padded.append('O' * len(t.form)) # 1음절\n",
    "            else:\n",
    "                padded.append('O' * len(t.form)) # 불용어 패딩\n",
    "        return padded, meaningful\n",
    "    except:\n",
    "        return [], []\n",
    "\n",
    "tqdm.pandas()\n",
    "print(\"전체 데이터 전처리 (Padding + LDA 토큰 추출)\")\n",
    "df[['tokens_padded', 'tokens_lda']] = df['text'].progress_apply(\n",
    "    lambda x: pd.Series(preprocess_dual(x))\n",
    ")"
   ],
   "id": "3d9a5a99194ec285",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 데이터 전처리 (Padding + LDA 토큰 추출)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50222/50222 [2:07:37<00:00,  6.56it/s]   \n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-09T13:46:30.363527Z",
     "start_time": "2025-12-09T13:39:53.600339Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 문서 길이 계산 (패딩 포함, x1 변수)\n",
    "df['doc_length'] = df['tokens_padded'].apply(lambda x: sum(len(t) for t in x))\n",
    "\n",
    "print(\"LDA 토픽 모델 학습 (전체 데이터)\")\n",
    "lda_tokens = df['tokens_lda'].tolist()\n",
    "dictionary = corpora.Dictionary(lda_tokens)\n",
    "dictionary.filter_extremes(no_below=20, no_above=0.5)\n",
    "corpus = [dictionary.doc2bow(text) for text in lda_tokens]\n",
    "\n",
    "# 토픽 수 10개 (도메인 분류용 x3)\n",
    "lda_model = LdaModel(\n",
    "    corpus=corpus,\n",
    "    id2word=dictionary,\n",
    "    num_topics=10,\n",
    "    random_state=42,\n",
    "    passes=5,\n",
    "    alpha='auto'\n",
    ")\n",
    "\n",
    "def get_topic_probs(tokens):\n",
    "    if not tokens:\n",
    "        return [0.1] * 10\n",
    "    bow = dictionary.doc2bow(tokens)\n",
    "    topics = lda_model.get_document_topics(bow, minimum_probability=0.0)\n",
    "    topic_vec = [0.0] * 10\n",
    "    for topic_id, prob in topics:\n",
    "        topic_vec[topic_id] = prob\n",
    "    return topic_vec\n",
    "\n",
    "print(\"토픽 확률 추론\")\n",
    "df['topic_probs'] = df['tokens_lda'].progress_apply(get_topic_probs)\n",
    "\n",
    "# 저장\n",
    "save_path = os.path.join(DATA_DIR, 'full_data.pkl')\n",
    "model_path = os.path.join(DATA_DIR, 'lda_full.model')\n",
    "\n",
    "df.to_pickle(save_path)\n",
    "lda_model.save(model_path)\n",
    "\n",
    "print(\"작업 완료\")\n",
    "print(f\"저장 경로: {save_path}\")\n",
    "print(\"\\n[LDA 토픽 예시]\")\n",
    "for idx, topic in lda_model.print_topics(3):\n",
    "    print(f\"Topic {idx}: {topic}\")"
   ],
   "id": "ebda95a387f019fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA 토픽 모델 학습 (전체 데이터)\n",
      "토픽 확률 추론\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50222/50222 [00:48<00:00, 1030.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "작업 완료\n",
      "저장 경로: ..\\final_data\\full_data.pkl\n",
      "\n",
      "[LDA 토픽 예시]\n",
      "Topic 8: 0.007*\"대통령\" + 0.006*\"사건\" + 0.005*\"정부\" + 0.005*\"경찰\" + 0.005*\"미국\" + 0.004*\"당시\" + 0.004*\"한국\" + 0.004*\"주장\" + 0.004*\"문제\" + 0.003*\"박근혜\"\n",
      "Topic 1: 0.009*\"시리즈\" + 0.007*\"캐릭터\" + 0.006*\"작품\" + 0.005*\"건담\" + 0.005*\"게임\" + 0.005*\"성우\" + 0.004*\"발매\" + 0.004*\"세계\" + 0.004*\"애니메이션\" + 0.004*\"설정\"\n",
      "Topic 4: 0.008*\"모습\" + 0.004*\"인간\" + 0.004*\"결국\" + 0.004*\"모르\" + 0.004*\"주인공\" + 0.004*\"만나\" + 0.004*\"죽이\" + 0.003*\"당하\" + 0.003*\"이야기\" + 0.003*\"친구\"\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
